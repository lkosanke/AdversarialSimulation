---
title: "AnalyzeResults"
author: "Valentin Kriegmair"
execute: 
  echo: false
format:
  pdf:
    documentclass: article
    margin-left: 1in
    margin-right: 1in
    margin-top: 1in
    margin-bottom: 1in
  html:
    toc: true
bibliography: ../../bibliography.bib
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(knitr)

```

library(dplyr) library(lavaan) library(purrr) library(kableExtra)

The following represents the evaluation and interpretation of the results generated by simulation study 1 and study 2 as a conceptual replication of @rosseel_structural_2022 and @dhaene_evaluation_2023.

```{r}
# Load the processed data
summary_1 <- readRDS("../simulation/results/summary_study1.rds")
```

# Study 1

## Overview

This study evaluated the performance of vanilla SEM compared to global SAM (gSAM), local SAM with maximum likelihood (lSAM-ML), and local SAM with unweighted least squares (lSAM-ULS) under various conditions:

-   **Sample sizes**: small (N = 100), moderate (N = 400), and large (N = 6400)
-   **Reliability levels**:
    -   Low reliability ($\lambda = 0.3$)
    -   Moderate reliability ($\lambda = 0.5$)
    -   High reliability ($\lambda = 0.7$)
-   **Estimation based on**: a 5-factor population structural model with 3 indicators for each factor
-   **Model specifications**:
    -   Correctly specified (Model 1.1)
    -   Mis-specified with omitted cross loadings (Model 1.2)
    -   Mis-specified with omitted correlated residuals (Model 1.3)
    -   Mis-specified with an inverted structural path (Model 1.4)

In all conditions, the population-level values of the structural parameters were set to 0.1. See [![DOI](https://camo.githubusercontent.com/346beb9c54d4cbcfa0fd6933e396d052bb0b9a0c2fc0086f3f4703e737c79d43/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e31313435383534372e737667){alt="DOI"}](https://doi.org/10.5281/zenodo.11458547) for more details on the data generating process.

## Convergence Rate

Table 1 - 4 below show convergence rates using each method - vanilla SEM, global SAM (gSAM), local SAM with maximum likelihood (lSAM-ML) and local SAM with unweighted least squares (lSAM-ULS) for different sample sizes and reliability under varying model (mis) - specifications.

For moderate and large sample sizes (N = 400, 6400), all methods achieve a 100% convergence rate. For a small sample size (N = 100), SEM shows lower convergence rates, particularly at lower reliability levels (0.3), while GSAM, SAM-ML, and SAM-ULS maintain high convergence rates. Higher reliability levels (0.5 and 0.7) generally correspond to higher convergence rates for all methods. SEM exhibits notable drops in convergence at the lowest reliability (0.3), especially under cross loadings (1.2) and structural (1.4) misspecification. GSAM, SAM-ML, and SAM-ULS consistently show robust performance across all conditions. The omitted cross loadings (1.2) are particularly challenging for SEM with a convergence rate of 72.34% at the smallest sample size and lowest reliability. These results suggest that GSAM, SAM-ML, and SAM-ULS are more reliable for achieving model convergence, especially in scenarios with smaller sample sizes and lower reliability than vanilla SEM estimation.

```{r}
# Table for model type 1.1
convergence_table_1_1 <- summary_1 %>%
  filter(model_type == "1.1") %>%
  select(N, reliability, method, ConvergenceRate) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Convergence Rate` = ConvergenceRate
  ) %>%
  mutate(
    `Convergence Rate` = round(`Convergence Rate`, 3),
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS")
  ) %>%
  pivot_wider(names_from = Method, values_from = `Convergence Rate`) %>%
  kbl(caption = "Convergence Rates under correct model specification (Model 1.1)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
convergence_table_1_1

# Table for model type 1.2
convergence_table_1_2 <- summary_1 %>%
  filter(model_type == "1.2") %>%
  select(N, reliability, method, ConvergenceRate) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Convergence Rate` = ConvergenceRate
  ) %>%
  mutate(
    `Convergence Rate` = round(`Convergence Rate`, 3),
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS")
  ) %>%
  pivot_wider(names_from = Method, values_from = `Convergence Rate`) %>%
  kbl(caption = "Convergence Rates funder omitted Cross Loadings (Model 1.2)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
convergence_table_1_2

# Table for model type 1.3
convergence_table_1_3 <- summary_1 %>%
  filter(model_type == "1.3") %>%
  select(N, reliability, method, ConvergenceRate) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Convergence Rate` = ConvergenceRate
  ) %>%
  mutate(
    `Convergence Rate` = round(`Convergence Rate`, 3),
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS")
  ) %>%
  pivot_wider(names_from = Method, values_from = `Convergence Rate`) %>%
  kbl(caption = "Convergence Rates under omitted Correlated Residuals (Model 1.3)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
convergence_table_1_3

# Table for model type 1.4
convergence_table_1_4 <- summary_1 %>%
  filter(model_type == "1.4") %>%
  select(N, reliability, method, ConvergenceRate) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Convergence Rate` = ConvergenceRate
  ) %>%
  mutate(
    `Convergence Rate` = round(`Convergence Rate`, 3),
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS")
  ) %>%
  pivot_wider(names_from = Method, values_from = `Convergence Rate`) %>%
  kbl(caption = "Convergence Rates under Structural Misspecification (Model 1.4)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
convergence_table_1_4


```

## Average Relative Biases (in Percentages)

Here this study diverges from the original of Rosseel (2022) by focusing exclusively on the average relative bias under a single type of correctly specified model (model 1), which does not include any cross loadings or correlated residuals. This simplification, allows to concentrate on the core advantage of SAM over traditional SEM: its more robust estimation of structural parameters, especially when measurement models are misspecified. By narrowing the scope, we aim to highlight SAM's robustness and its potential as a superior alternative in scenarios where traditional SEM may falter.

The tables 5 - 8 below show average relative bias in percentages using each method for different reliability values and sample sizes under varying model (mis) - specification. For the correct (1.1) model, SEM generally shows higher biases at smaller sample sizes and lower reliability, while GSAM, SAM-ML, and SAM-ULS exhibit lower biases. Under cross loadings (1.2) model shows substantial biases for all methods, especially at smaller sample sizes and lower reliability, with SEM displaying the highest biases. For the correlated residuals (1.3) model, negative biases are observed, with SEM consistently showing the highest negative biases, while GSAM, SAM-ML, and SAM-ULS perform better. The structural (1.4) model shows that SEM has the highest biases at lower sample sizes and reliability, while GSAM, SAM-ML, and SAM-ULS have relatively lower and similar biases. Overall, GSAM, SAM-ML, and SAM-ULS are more robust and exhibit lower biases compared to SEM, especially in challenging conditions with smaller sample sizes and lower reliability.

```{r}
# Table for model type 1.1
bias_table_1_1 <- summary_1 %>%
  filter(model_type == "1.1") %>%
  select(N, reliability, method, MeanRelativeBias) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Relative Bias (%)` = MeanRelativeBias
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "gSAM", 
                    lSAM_ML = "lSAM-ML", 
                    lSAM_ULS = "lSAM-ULS"),
    `Average Relative Bias (%)` = round(`Average Relative Bias (%)` * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Relative Bias (%)`) %>%
  kbl(caption = "Average Relative Biases (in Percentages) under correct model specification (Model 1.1)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
bias_table_1_1

# Table for model type 1.2
bias_table_1_2 <- summary_1 %>%
  filter(model_type == "1.2") %>%
  select(N, reliability, method, MeanRelativeBias) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Relative Bias (%)` = MeanRelativeBias
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "gSAM", 
                    lSAM_ML = "lSAM-ML", 
                    lSAM_ULS = "lSAM-ULS"),
    `Average Relative Bias (%)` = round(`Average Relative Bias (%)` * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Relative Bias (%)`) %>%
  kbl(caption = "Average Relative Biases (in Percentages) funder omitted Cross Loadings (Model 1.2)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
bias_table_1_2

# Table for model type 1.3
bias_table_1_3 <- summary_1 %>%
  filter(model_type == "1.3") %>%
  select(N, reliability, method, MeanRelativeBias) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Relative Bias (%)` = MeanRelativeBias
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "gSAM", 
                    lSAM_ML = "lSAM-ML", 
                    lSAM_ULS = "lSAM-ULS"),
    `Average Relative Bias (%)` = round(`Average Relative Bias (%)` * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Relative Bias (%)`) %>%
  kbl(caption = "Average Relative Biases (in Percentages) under omitted Correlated Residuals (Model 1.3)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
bias_table_1_3

# Table for model type 1.4
bias_table_1_4 <- summary_1 %>%
  filter(model_type == "1.4") %>%
  select(N, reliability, method, MeanRelativeBias) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Relative Bias (%)` = MeanRelativeBias
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "gSAM", 
                    lSAM_ML = "lSAM-ML", 
                    lSAM_ULS = "lSAM-ULS"),
    `Average Relative Bias (%)` = round(`Average Relative Bias (%)` * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Relative Bias (%)`) %>%
  kbl(caption = "Average Relative Biases (in Percentages) under Structural Misspecification (Model 1.4)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
bias_table_1_4
```

## Coverage

The tables 9 - 12 show the average difference between empirical coverage levels of the 95% confidence intervals (CIs) and their nominal level (95%) using each method for different reliability values and sample sizes under varying model (mis) - specification.

For the correct (1.1) model, SEM shows undercoverage at smaller sample sizes and lower reliability, such as -1.839% at N=100 and reliability 0.3, indicating narrow CIs and less reliable parameter estimates. GSAM, SAM-ML, and SAM-ULS tend to exhibit slight overcoverage, with values like 3.104%, 3.151%, and 2.701%, respectively, indicating more conservative estimates. Under the cross loadings (1.2) model, all methods display substantial undercoverage, particularly SEM, which shows values as low as -65.231% at N=6400 and reliability 0.3. This highlights the challenge of this model mis-specification. Correlated residuals (Model 1.3) model reveal consistent undercoverage across all methods, with SEM showing the highest negative biases, such as -87.016% at N=6400 and reliability 0.3. The structural (1.4) model indicates that SEM suffers from undercoverage at lower sample sizes and reliability, with -1.471% at N=100 and reliability 0.3, while GSAM, SAM-ML, and SAM-ULS perform better with relatively lower and more consistent biases. For example, GSAM shows 3.293% at the same conditions. Overall, GSAM, SAM-ML, and SAM-ULS demonstrate better empirical coverage than SEM, but significant biases still exist under certain mis-specifications

```{r}
# Table for model type 1.1
coverage_diff_table_1_1 <- summary_1 %>%
  filter(model_type == "1.1") %>%
  select(N, reliability, method, MeanCoverage) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Coverage Difference (%)` = MeanCoverage
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average Coverage Difference (%)` = round((`Average Coverage Difference (%)` - 0.95) * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Coverage Difference (%)`) %>%
  kbl(caption = "Average Coverage Difference (in Percentages) under correct model specification (Model 1.1)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
coverage_diff_table_1_1

# Table for model type 1.2
coverage_diff_table_1_2 <- summary_1 %>%
  filter(model_type == "1.2") %>%
  select(N, reliability, method, MeanCoverage) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Coverage Difference (%)` = MeanCoverage
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average Coverage Difference (%)` = round((`Average Coverage Difference (%)` - 0.95) * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Coverage Difference (%)`) %>%
  kbl(caption = "Average Coverage Difference (in Percentages) funder omitted Cross Loadings (Model 1.2)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
coverage_diff_table_1_2

# Table for model type 1.3
coverage_diff_table_1_3 <- summary_1 %>%
  filter(model_type == "1.3") %>%
  select(N, reliability, method, MeanCoverage) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Coverage Difference (%)` = MeanCoverage
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average Coverage Difference (%)` = round((`Average Coverage Difference (%)` - 0.95) * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Coverage Difference (%)`) %>%
  kbl(caption = "Average Coverage Difference (in Percentages) under omitted Correlated Residuals (Model 1.3)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
coverage_diff_table_1_3

# Table for model type 1.4
coverage_diff_table_1_4 <- summary_1 %>%
  filter(model_type == "1.4") %>%
  select(N, reliability, method, MeanCoverage) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average Coverage Difference (%)` = MeanCoverage
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average Coverage Difference (%)` = round((`Average Coverage Difference (%)` - 0.95) * 100, 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average Coverage Difference (%)`) %>%
  kbl(caption = "Average Coverage Difference (in Percentages) under Structural Misspecification (Model 1.4)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
coverage_diff_table_1_4


```

## RMSE

Next the tables 13 - 16 below shows the average RMSE multiplied by the square root of N using each method for different reliability values and sample sizes under varying model (mis) - specification.

For the correct (1.1) model, SEM generally shows higher RMSE values at smaller sample sizes and lower reliability, such as 27.153 at N=100 and reliability 0.3. GSAM, SAM-ML, and SAM-ULS demonstrate lower RMSE values, indicating better performance. As the sample size increases, all methods show improved performance, with RMSE values becoming more similar across methods. Under the cross loadings (1.2) model, SEM shows significantly higher RMSE values, indicating poor performance, such as 137.409 at N=6400 and reliability 0.3. GSAM, SAM-ML, and SAM-ULS also exhibit increased RMSE values under this model mis-specification, but they perform better than SEM. The correlated residuals (1.3) model shows that SEM consistently has higher RMSE values across all conditions, such as 16.896 at N=100 and reliability 0.3. GSAM, SAM-ML, and SAM-ULS perform better, though still showing increased RMSE values under larger sample sizes, such as 43.446 at N=6400 and reliability 0.3 for SEM. For the structural (1.4) model, SEM has higher RMSE values at lower sample sizes and reliability, such as 33.608 at N=100 and reliability 0.3, while GSAM, SAM-ML, and SAM-ULS demonstrate lower RMSE values. As sample sizes increase, the RMSE values for all methods become more consistent, though SEM still tends to show higher values compared to the other methods.

Overall, GSAM, SAM-ML, and SAM-ULS demonstrate better performance with lower RMSE values compared to SEM, particularly in challenging conditions with smaller sample sizes and lower reliability. However, all methods show increased RMSE values under certain model mis-specifications

```{r}
# Table for model type 1.1
rmse_table_1_1 <- summary_1 %>%
  filter(model_type == "1.1") %>%
  select(N, reliability, method, MeanRelativeRMSE) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average RMSE * sqrt(N)` = MeanRelativeRMSE
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average RMSE * sqrt(N)` = round(`Average RMSE * sqrt(N)` * sqrt(N), 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average RMSE * sqrt(N)`) %>%
  kbl(caption = "Average RMSE multiplied by √N under correct model specification (Model 1.1)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
rmse_table_1_1

# Table for model type 1.2
rmse_table_1_2 <- summary_1 %>%
  filter(model_type == "1.2") %>%
  select(N, reliability, method, MeanRelativeRMSE) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average RMSE * sqrt(N)` = MeanRelativeRMSE
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average RMSE * sqrt(N)` = round(`Average RMSE * sqrt(N)` * sqrt(N), 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average RMSE * sqrt(N)`) %>%
  kbl(caption = "Average RMSE multiplied by √N funder omitted Cross Loadings (Model 1.2)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
rmse_table_1_2

# Table for model type 1.3
rmse_table_1_3 <- summary_1 %>%
  filter(model_type == "1.3") %>%
  select(N, reliability, method, MeanRelativeRMSE) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average RMSE * sqrt(N)` = MeanRelativeRMSE
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average RMSE * sqrt(N)` = round(`Average RMSE * sqrt(N)` * sqrt(N), 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average RMSE * sqrt(N)`) %>%
  kbl(caption = "Average RMSE multiplied by √N under omitted Correlated Residuals (Model 1.3)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
rmse_table_1_3

# Table for model type 1.4
rmse_table_1_4 <- summary_1 %>%
  filter(model_type == "1.4") %>%
  select(N, reliability, method, MeanRelativeRMSE) %>%
  rename(
    Reliability = reliability,
    Method = method,
    `Average RMSE * sqrt(N)` = MeanRelativeRMSE
  ) %>%
  mutate(
    Method = recode(Method, 
                    SEM = "SEM", 
                    gSAM = "GSAM", 
                    lSAM_ML = "SAM-ML", 
                    lSAM_ULS = "SAM-ULS"),
    `Average RMSE * sqrt(N)` = round(`Average RMSE * sqrt(N)` * sqrt(N), 3)
  ) %>%
  pivot_wider(names_from = Method, values_from = `Average RMSE * sqrt(N)`) %>%
  kbl(caption = "Average RMSE multiplied by √N under Structural Misspecification (Model 1.4)",
      format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

rmse_table_1_4
```

## Improper Solutions

Improper solutions occur when parameter estimates fall outside the boundary of the parameter space, such as when variances are estimated to be negative or correlations exceed an absolute value of one. These issues are more likely to arise in smaller sample sizes and can indicate problems with model estimation.

The tables 17 - 20 below show the count of improper solutions across different conditions. It is evident that SEM exhibits a significantly higher count of improper solutions compared to GSAM, SAM-ML, and SAM-ULS, especially in small sample sizes and lower reliability conditions. For example, under the correct model specification (model 1.1) with a sample size of 100 and reliability of 0.3, SEM has 27.30% improper solutions, whereas GSAM, SAM-ML, and SAM-ULS have negligible or no improper solutions. This pattern is consistent across all model mis-specifications, with SEM frequently encountering improper solutions in challenging conditions. In contrast, GSAM, SAM-ML, and SAM-ULS demonstrate robust performance with minimal improper solutions across all scenarios, highlighting their reliability in parameter estimation.

```{r}
# Table for model type 1.1
improper_solutions_table_1_1 <- detailed_results_1 %>%
  filter(model_type == "1.1") %>%
  group_by(N, reliability, method) %>%
  summarise(
    ImproperSolutionsCount = sum(ImproperSolution, na.rm = TRUE) / 10000 * 100,
    .groups = 'drop'
  ) %>%
  pivot_wider(names_from = method, values_from = ImproperSolutionsCount) %>%
  rename(
    Reliability = reliability,
    N = N
  ) %>%
  kbl(caption = "Percentage of Improper Solutions under correct model specification (Model 1.1)",
      format = "html", booktabs = TRUE, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
improper_solutions_table_1_1

# Table for model type 1.2
improper_solutions_table_1_2 <- detailed_results_1 %>%
  filter(model_type == "1.2") %>%
  group_by(N, reliability, method) %>%
  summarise(
    ImproperSolutionsCount = sum(ImproperSolution, na.rm = TRUE) / 10000 * 100,
    .groups = 'drop'
  ) %>%
  pivot_wider(names_from = method, values_from = ImproperSolutionsCount) %>%
  rename(
    Reliability = reliability,
    N = N
  ) %>%
  kbl(caption = "Percentage of Improper Solutions funder omitted Cross Loadings (Model 1.2)",
      format = "html", booktabs = TRUE, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
improper_solutions_table_1_2

# Table for model type 1.3
improper_solutions_table_1_3 <- detailed_results_1 %>%
  filter(model_type == "1.3") %>%
  group_by(N, reliability, method) %>%
  summarise(
    ImproperSolutionsCount = sum(ImproperSolution, na.rm = TRUE) / 10000 * 100,
    .groups = 'drop'
  ) %>%
  pivot_wider(names_from = method, values_from = ImproperSolutionsCount) %>%
  rename(
    Reliability = reliability,
    N = N
  ) %>%
  kbl(caption = "Percentage of Improper Solutions under omitted Correlated Residuals (Model 1.3)",
      format = "html", booktabs = TRUE, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
improper_solutions_table_1_3

# Table for model type 1.4
improper_solutions_table_1_4 <- detailed_results_1 %>%
  filter(model_type == "1.4") %>%
  group_by(N, reliability, method) %>%
  summarise(
    ImproperSolutionsCount = sum(ImproperSolution, na.rm = TRUE) / 10000 * 100,
    .groups = 'drop'
  ) %>%
  pivot_wider(names_from = method, values_from = ImproperSolutionsCount) %>%
  rename(
    Reliability = reliability,
    N = N
  ) %>%
  kbl(caption = "Percentage of Improper Solutions under Structural Misspecification (Model 1.4)",
      format = "html", booktabs = TRUE, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# Display the table
improper_solutions_table_1_4
```
