
---
title: "Study 1"
author: "Valentin Kriegmair"
date: '2024-04-21'
output: html_document
---

Remarks:
- This is yet in a combined markdown format but will be split into separate files.
- The study does not include all methods and performance metrics.
- At the moment this only runs locally.
- Once this basic structure of the script is confirmed the remaining methods and metrics will be added as well as the second study and the script will be set up to run on a cluster.

Questions:
- Is the general approach sound?
- Am I correctly using the `future` and `furrr` packages for parallel processing?
- Does this need major alterations to run on the cluster?

# Libraries
will be handled by docker or renv
```{r}
library(MASS)  
library(dplyr) 
library(tidyr) 
library(future) 
library(furrr)
library(lavaan)
library(purrr)
library(parallel)
```

# Setup
```{r}
RNGkind("L'Ecuyer-CMRG")
plan(multisession, workers = detectCores() - 1)
```


# Data Generating Mechanism:
```{r}
library(lavaan)
library(Matrix)

gen_mat <- function(model_type, nfactors = 5, nvar.factor = 3, lambda = 0.70, 
                                         beta_value = 0.1, psi.cor = 0.3, reliability = 0.80, 
                                         rho = 0.80) {
  
  # 1. LAMBDA
  fac <- matrix(c(1, rep(lambda, times = (nvar.factor - 1L))), nvar.factor, 1L)
  LAMBDA <- bdiag(rep(list(fac), nfactors))
  
  if (model_type == "1.2") {
    # misspecification in the measurement part: cross-loadings
    i.cross <- (0:(nfactors-1)) * nvar.factor + ceiling(nvar.factor / 2)
    for (j in 1:ncol(LAMBDA)) {
      LAMBDA[i.cross[j], c(2:nfactors, 1)[j]] <- rho * lambda
    }
  }
  
  LAMBDA <- as.matrix(LAMBDA)
  
  # 2. BETA
  BETA <- matrix(0, nrow = nfactors, ncol = nfactors)
  BETA[3:5, 1] <- BETA[3:4, 2] <- BETA[5, 3] <- BETA[c(3, 5), 4] <- beta_value
  if (model_type == "1.4") {
    # misspecification in the structural part for model 1.4
    BETA[4, c(1, 2, 3)] <- 0.1
  } else if (model_type == "1.3") {
    # misspecification in the structural part for model 1.3
    BETA[4, 3] <- BETA[3, 4]
    BETA[3, 4] <- 0
  }
  BETA.model <- BETA  # Structural part to be fitted
  VAL <- BETA[BETA != 0]  # true values
  
  # 3. PSI
  PSI <- matrix(0, nrow = nfactors, ncol = nfactors)
  PSI[1, 1] <- PSI[2, 2] <- 1  # the exogenous latent variables
  RES <- (1 - beta_value^2)
  PSI[lav_matrix_diag_idx(nfactors)[-c(1:2)]] <- RES
  
  # Calculate VETA
  IB_inv <- solve(diag(nfactors) - BETA)
  Sigma_eta <- IB_inv %*% PSI %*% t(IB_inv)
  
  # 4. THETA
  tmp <- diag(LAMBDA %*% Sigma_eta %*% t(LAMBDA))
  theta_diag <- tmp / reliability - tmp
  stopifnot(all(theta_diag > 0))
  THETA <- matrix(0, nrow(LAMBDA), nrow(LAMBDA))
  diag(THETA) <- theta_diag
  
  if (model_type == "1.3") {
    pairs <- cbind(c(2, 5, 8, 11, 14), c(3, 6, 9, 12, 15))
    for (pair in 1:nrow(pairs)) {
      i <- pairs[pair, 1]
      j <- pairs[pair, 2]
      THETA[i, j] <- THETA[j, i] <- 0.6 * min(theta_diag[c(i, j)])
    }
  }
  
  MLIST <- list(lambda = LAMBDA, theta = THETA, psi = PSI, beta = BETA)
  
  return(MLIST)
}

# Utility function to get diagonal indices
lav_matrix_diag_idx <- function(n) {
  return(seq(1, n^2, by = n + 1))
}


##############--------------------------------------###############

# Function to generate Lavaan model syntax from model matrices
gen_pop_model_syntax <- function(MLIST, ov.prefix = "y", lv.prefix = "f", include.values = TRUE) {
  
  LAMBDA <- MLIST$lambda
  THETA  <- MLIST$theta
  PSI    <- MLIST$psi
  BETA   <- MLIST$beta
  
  # Check prefix
  if (ov.prefix == lv.prefix) {
    stop("lavaan ERROR: ov.prefix can not be the same as lv.prefix")
  }
  
  header <- "# syntax generated by gen_pop_model_syntax()"
  
  # LAMBDA
  if (!is.null(LAMBDA)) {
    IDXV <- row(LAMBDA)[(LAMBDA != 0)]
    IDXF <- col(LAMBDA)[(LAMBDA != 0)]
    
    IDXV <- as.integer(sapply(unique(IDXF), function(j) {
      ji <- IDXV[which(IDXF == j)]  # non-zero loadings for factor j
      j1 <- which(abs(LAMBDA[ji, j] - 1) < .Machine$double.eps)
      ji[c(1, j1)] <- ji[c(j1, 1)]
      return(ji)
    }))
    
    nel <- length(IDXF)
    lambda.txt <- character(nel)
    for (i in seq_len(nel)) {
      if (include.values) {
        lambda.txt[i] <- paste0(paste0(lv.prefix, IDXF[i]), " =~ ",
                                LAMBDA[IDXV[i], IDXF[i]], "*",
                                paste0(ov.prefix, IDXV[i]))
      } else {
        lambda.txt[i] <- paste0(paste0(lv.prefix, IDXF[i]), " =~ ",
                                paste0(ov.prefix, IDXV[i]))
      }
    }
  } else {
    lambda.txt <- character(0L)
  }
  
  # THETA
  if (!is.null(THETA)) {
    IDX1 <- row(THETA)[(THETA != 0) & upper.tri(THETA, diag = TRUE)]
    IDX2 <- col(THETA)[(THETA != 0) & upper.tri(THETA, diag = TRUE)]
    nel <- length(IDX1)
    theta.txt <- character(nel)
    for (i in seq_len(nel)) {
      if (include.values) {
        theta.txt[i] <- paste0(paste0(ov.prefix, IDX1[i]), " ~~ ",
                               THETA[IDX1[i], IDX2[i]], "*",
                               paste0(ov.prefix, IDX2[i]))
      } else {
        theta.txt[i] <- paste0(paste0(ov.prefix, IDX1[i]), " ~~ ",
                               paste0(ov.prefix, IDX2[i]))
      }
    }
  } else {
    theta.txt <- character(0L)
  }
  
  # PSI
  if (!is.null(PSI)) {
    IDX1 <- row(PSI)[(PSI != 0) & upper.tri(PSI, diag = TRUE)]
    IDX2 <- col(PSI)[(PSI != 0) & upper.tri(PSI, diag = TRUE)]
    nel <- length(IDX1)
    psi.txt <- character(nel)
    for (i in seq_len(nel)) {
      if (include.values) {
        psi.txt[i] <- paste0(paste0(lv.prefix, IDX1[i]), " ~~ ",
                             PSI[IDX1[i], IDX2[i]], "*",
                             paste0(lv.prefix, IDX2[i]))
      } else {
        psi.txt[i] <- paste0(paste0(lv.prefix, IDX1[i]), " ~~ ",
                             paste0(lv.prefix, IDX2[i]))
      }
    }
  } else {
    psi.txt <- character(0L)
  }
  
  # BETA
  if (!is.null(BETA)) {
    IDX1 <- row(BETA)[(BETA != 0)]
    IDX2 <- col(BETA)[(BETA != 0)]
    nel <- length(IDX1)
    beta.txt <- character(nel)
    for (i in seq_len(nel)) {
      if (include.values) {
        beta.txt[i] <- paste0(paste0(lv.prefix, IDX1[i]), " ~ ",
                              BETA[IDX1[i], IDX2[i]], "*",
                              paste0(lv.prefix, IDX2[i]))
      } else {
        beta.txt[i] <- paste0(paste0(lv.prefix, IDX1[i]), " ~ ",
                              paste0(lv.prefix, IDX2[i]))
      }
    }
  } else {
    beta.txt <- character(0L)
  }
  
  # Assemble
  syntax <- paste(c(header, lambda.txt, theta.txt, psi.txt, beta.txt, ""),
                  collapse = "\n")
  
  return(syntax)
}

# Data generation function
gen_pop_model_data <- function(model_type, N, reliability) {
  # Generate matrices and syntax
  matrices <- gen_mat(model_type, reliability = reliability)
  syntax <- gen_pop_model_syntax(matrices)
  
  # Generate data using lavaan's simulateData function
  data <- simulateData(model = syntax, sample.nobs = N)
  
  return(list(data = data, syntax = syntax, matrices = matrices))
}
```



```{r}
# Define the number of repetitions
n_reps <- 10 

# Parameter Grid

# let the furrr jobs reiterate walk not walk over each row of the grid
# what would be each repitititon x condition but only over each repitition
# and all conditions within. Then write a file for each results from this
# as otherwise this file.

# Function to generate seeds
parallel_seeds <- function(n, seed = NULL) {
  if (is.null(seed))
    stop("seed must be provided.")
  RNGkind("L'Ecuyer-CMRG")
  set.seed(seed)
  purrr::accumulate(seq_len(n - 1), function(s, x) parallel::nextRNGStream(s), 
                    .init = .Random.seed)
}

# Generate parameters grid with seeds
n_reps <- 10
params <- expand.grid(
  model_type = c("1.1", "1.2", "1.3", "1.4"),
  N = c(100, 400, 6400),
  reliability = c(0.3, 0.5, 0.7),
  method = c("SEM", "SAM"),
  rep = 1:n_reps
) %>%
  mutate(seed = rep(parallel_seeds(n_reps, seed = 42), length.out = n()))

# Set population values
B_true <- c(
  'f3~f1' = 0.1, 'f3~f2' = 0.1, 'f3~f4' = 0.1,
  'f4~f1' = 0.1, 'f4~f2' = 0.1,
  'f5~f3' = 0.1, 'f5~f4' = 0.1
)
true_values <- list(
  B = B_true
)

model_syntax <- "    
    f1 =~ y1 + y2 + y3
    f2 =~ y4 + y5 + y6
    f3 =~ y7 + y8 + y9
    f4 =~ y10 + y11 + y12
    f5 =~ y13 + y14 + y15
    
    f3 ~ f1 + f2 + f4
    f4 ~ f1 + f2
    f5 ~ f3 + f4"
```

# Study 1 all metrics
```{r}
# Function to calculate coverage of confidence intervals
calculate_coverage <- function(fit, true_values) {
  if (is.null(fit) || !lavInspect(fit, "converged")) {
    return(NA)
  }
  # Extract parameter estimates with confidence intervals
  param_estimates <- parameterEstimates(fit)
  # Filter for the paths of interest
  param_estimates <- param_estimates %>%
    filter(lhs %in% c("f3", "f4", "f5") & op == "~")
  
  coverage <- sapply(names(true_values$B), function(param) {
    parts <- unlist(strsplit(param, "~"))
    row <- param_estimates %>%
      filter(lhs == parts[1], rhs == parts[2])
    if (nrow(row) > 0) {
      row$ci.lower <= true_values$B[param] && row$ci.upper >= true_values$B[param]
    } else {
      NA
    }
  })
  mean(coverage, na.rm = TRUE)
}


# Study function
run_study_1 <- function(params, true_values) {
  
  # Wrap the run_analysis function with safely and quietly
  run_analysis <- function(data, model_syntax, method = "SEM") {
    if (method == "SEM") {
      fit <- sem(model_syntax, data = as.data.frame(data))
    } else if (method == "SAM") {
      fit <- sam(model_syntax, data = as.data.frame(data))
    } else {
      stop("Unknown method specified")
    }
    return(fit)
  }

  # Function to fit model to population matrix
  run_sanity_check <- function(model_type, model_syntax) {
    popmodel <- gen_pop_model_syntax(MLIST = gen_mat(model_type = model_type))
    fit0 <- sem(model = popmodel, do.fit = FALSE)
    COV <- inspect(fit0, what = "implied")$cov[,]
    sanity_check_fit <- sem(sample.cov = COV, model = model_syntax, sample.nobs = 10^6)
    sanity_check_estimates <- coef(sanity_check_fit)
    names(sanity_check_estimates) <- paste0(names(sanity_check_estimates), "_pop")
    return(sanity_check_estimates)
  }

  safe_quiet_run_analysis <- safely(quietly(run_analysis))

  # Run the simulations and analysis in parallel
  results <- future_pmap(params, function(model_type, N, reliability, method, rep, seed, id) {
    set.seed(seed)
    data <- gen_pop_model_data(model_type, N, reliability)$data
    fit_result <- safe_quiet_run_analysis(data, model_syntax, method)
    sanity_check_estimates <- run_sanity_check(model_type, model_syntax)

    if (!is.null(fit_result$result$result) && lavInspect(fit_result$result$result, "converged")) {
      PT <- parTable(fit_result$result$result)
      estimated_paths <- PT[PT$op == "~", "est"]
      names(estimated_paths) <- paste0(PT[PT$op == "~", "lhs"], "~", PT[PT$op == "~", "rhs"])
      list(
        Converged = 1, NonConverged = 0, 
        EstimatedPaths = list(estimated_paths),
        SanityCheck = list(sanity_check_estimates),
        Warnings = toString(fit_result$result$warnings), 
        Messages = toString(fit_result$result$messages),
        Errors = if (is.null(fit_result$error)) NA_character_ else toString(fit_result$error$message)
      )
    } else {
      list(
        Converged = 0, NonConverged = 1, 
        EstimatedPaths = list(setNames(rep(NA, length(true_values$B)), names(true_values$B))),
        SanityCheck = list(sanity_check_estimates),
        Warnings = toString(fit_result$result$warnings), 
        Messages = toString(fit_result$result$messages),
        Errors = if (is.null(fit_result$error)) NA_character_ else toString(fit_result$error$message)
      )
    }
  }, .options = furrr_options(seed = params$seed))

  # Print the structure of results to debug
  print(str(results[[1]]))  # Print the structure of the first result

  # Create a dataframe for results
  results_df <- params %>%
    mutate(
      Converged = map_dbl(results, ~ .x$Converged),
      NonConverged = map_dbl(results, ~ .x$NonConverged),
      Warnings = map_chr(results, ~ .x$Warnings),
      Messages = map_chr(results, ~ .x$Messages),
      Errors = map_chr(results, ~ .x$Errors),
      EstimatedPaths = map(results, ~ .x$EstimatedPaths[[1]]),
      SanityCheck = map(results, ~ .x$SanityCheck[[1]])
    )

  # Calculate summary statistics
  summary_stats <- results_df %>%
    group_by(model_type, N, reliability, method) %>%
    summarise(
      ConvergenceRate = mean(Converged),
      NonConvergenceCount = sum(NonConverged),
      n_converged = sum(Converged),
      .groups = 'drop'
    ) %>%
    arrange(model_type, N, reliability, method)

  # Return the summary statistics and detailed results
  list(Summary = summary_stats, DetailedResults = results_df)
}

# Example usage (make sure to implement `generate_dgm`):
# results <- run_study_1(params, true_values)
```

# Results
```{r}
# Run the complete simulation study
simulation_results <- run_study_1(params, true_values)
simulation_results$Summary
```
