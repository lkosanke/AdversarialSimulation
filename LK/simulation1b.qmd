# First script for Simulation Study 1b

```{r}
set.seed(1)
```

# Packages

Copied and pasted from original paper.

```{r}
# Specify the libraries to load
libraries <- c("GPArotation", "CDM", "miceadds", "TAM", "sirt", "lavaan", "dplyr", "tidyr", "purrr", "tidyverse", "furrr")
# Set the R mirror to the cloud mirror of RStudio
options(repos = "https://cloud.r-project.org/")

# Load the libraries
for (library_name in libraries) {
  if (!require(library_name, character.only = TRUE)) {
    install.packages(library_name)
    library(library_name, character.only = TRUE)
  }
}
```

# Specify 2-factor-Model
```{r}
model <- "

#Structural part
    FX =~ l1*X1 + l2*X2 + l3*X3
    FY =~ l4*Y1 + l5*Y2 + l6*Y3
    FX ~~ 1*FX    #Fixed latent variance
    FY ~~ 1*FY    #Fixed latent variance
    FX ~~ phi*FY
    phi < 0.99    #Phi between -1 and 1
    phi > -0.99

#Measurement part    
    X1 ~~ vX1*X1
    X2 ~~ vX2*X2    
    X3 ~~ vX3*X3
    Y1 ~~ vY1*Y1
    Y2 ~~ vY2*Y2    
    Y3 ~~ vY3*Y3
    l1 > 0.01     #only positive loadings
    l2 > 0.01    
    l3 > 0.01
    l4 > 0.01
    l5 > 0.01
    l6 > 0.01       
    vX1 > 0.01    #only positive variances
    vX2 > 0.01    
    vX3 > 0.01
    vY1 > 0.01
    vY2 > 0.01    
    vY3 > 0.01
                #residual correlations
    X1 ~~ Y1
    X2 ~~ Y2
    "
```

# Setup and Design

```{r}
setup_design <- function() {
  
  #N
  N_sizes <- c(50, 100)
  
  # Factor loadings
  lambda_values <- c(0.4, 0.5, 0.6, 0.7, 0.8)
  
  # Factor correlations
  phi_values <- c(0, 0.2, 0.4, 0.6, 0.8)
  
  # Expand grid to create a data frame of all combinations
  design <- expand.grid(N = N_sizes, 
                        lambda = lambda_values, 
                        phi = phi_values)
  
  return(design)
}


```

# Data generating Mechanism

## Fixed values
No fixed values

## Varying values
```{r}
get_dgm <- function(lambda, phi) {
  # Factor loadings for all six manifest variables set to the specified lambda
  LAM <- matrix(c(lambda, lambda, lambda, lambda, lambda, lambda), nrow = 6, ncol = 2, byrow = TRUE)
  LAM[1:3, 2] <- 0  # Setting off-diagonal elements to 0
  LAM[4:6, 1] <- 0  
  
  # Factor correlation matrix
  PHI <- matrix(c(1, phi, phi, 1), nrow = 2, ncol = 2)
  
  # Theta
  error_variances <- 1 - lambda^2  
  THETA <- diag(c(rep(error_variances, 6)))  
  
  # residual correlations are directly specified 
  THETA[1, 4] <- THETA[4, 1] <- 0.12  
  THETA[2, 5] <- THETA[5, 2] <- 0.12 

  MLIST <-list(LAM = LAM, PHI = PHI, THETA = THETA)
  return(MLIST)
}


```

# Apply Syntax
```{r}
apply_syntax <- function(MLIST) {
  
  LAM <- MLIST$LAM
  PHI <- MLIST$PHI
  THETA <- MLIST$THETA
  
  pop.model <- paste(
"#Structural part",
    paste("FX =~", LAM[1,1], "*X1 +", LAM[2,1], "*X2 +", LAM[3,1], "*X3"),
    paste("FY =~", LAM[4,2], "*Y1 +", LAM[5,2], "*Y2 +", LAM[6,2], "*Y3"),
    "FX ~~ 1*FX",    
    "FY ~~ 1*FY",    
    paste("FX ~~", PHI[1,2], "*FY"),
"#Measurement part",    
    paste("X1 ~~", THETA[1,1], "*X1"),
    paste("X2 ~~", THETA[2,2], "*X2"),
    paste("X3 ~~", THETA[3,3], "*X3"),
    paste("Y1 ~~", THETA[4,4], "*Y1"),
    paste("Y2 ~~", THETA[5,5], "*Y2"),
    paste("Y3 ~~", THETA[6,6], "*Y3"),
"Correlated residuals",
    paste("X1 ~~", THETA[1,4], "*Y1"),
    paste("X2 ~~", THETA[2,5], "*Y2"),
    sep = "\n"
  ) 
 
  return(pop.model)
}

model_syntax <-apply_syntax(get_dgm(0.4,0.2))
cat(model_syntax)

```


# Simulate data
```{r}
simulate_data <- function(N, lambda, phi) {

  dgm_params <- get_dgm(lambda, phi)
  
  pop.model <- apply_syntax(dgm_params)
  
  df_dat <- simulateData(pop.model, sample.nobs = N)
  
  return(df_dat)
}

```

# Planned Analysis
```{r}
#Specify estimation methods of interest

estimators <- list(
  LSAM_ML = \(d) lavaan::sam(model, data=d, sam.method="local", estimator = "ML", std.lv= TRUE),
  LSAM_ULS = \(d)lavaan::sam(model, data=d, sam.method="local", estimator = "ULS", std.lv= TRUE)
)
# postprocess each model output
estimators <- modify(estimators, ~compose(\(e)filter(e, label == "phi")$est, parameterEstimates, .))
# apply all estimators to the same dataset
apply_estimators <- \(d) map(estimators, exec, d)

planned_analysis <- compose(apply_estimators, simulate_data)

planned_analysis(100, 0.4, 0.2)

```
# Extract results

```{r}

extract_results <- function(results_df_raw){

# New coloumn for methods
results_long <- results_df_raw %>%
     pivot_longer(cols = starts_with("LSAM"), 
                  names_to = c("method", "metric"), 
                  names_sep = "_",
                  values_to = "value") %>%
     unite("method_metric", method, metric, sep = "_")
  
# Split metrics by N into separate lists
  split_metrics <- split(results_long, results_long$N)

process_each_N <- function(data) {
    # Split metrics by Estimators
    estimator_splits <- data %>%
      group_by(method_metric) %>%
      group_split() %>%
      set_names(map(., ~paste(unique(.x$method_metric))))

    # Calculate metrics for each estimator
    results_metric <- map(estimator_splits, function(df) {
        df %>%
          group_by(N, lambda, phi, method_metric) %>%
    summarize(across(everything(),
       list(
          abs_bias = ~mean(abs(.x - phi)),              # Average absolute bias
          se_bias = ~(sd(abs(.x - phi)))/ sqrt(unique(N)),      # SE of bias
          ci_lower = ~(mean(abs(.x - phi)) - qt(0.975, df = unique(N) - 1) * (sd(abs(.x - phi)))/ sqrt(unique(N))),  # Lower CI
          ci_upper = ~(mean(abs(.x - phi)) + qt(0.975, df = unique(N) - 1) * (sd(abs(.x - phi)))/ sqrt(unique(N)))   # Upper CI
                    )),  .groups = 'drop')
    })
    
    return(results_metrics)
  }
  
 # Split further by each estimator and transform
  metrics_list <- map(split_metrics, process_each_N)

  return(metrics_list)
}

```

# Report Bias

```{r}
report_bias <- function(metrics_list) {
  # Define a list to store results
  bias_ci <- list()
  
  # Iterate over each condition in metrics_list
  for (condition in names(metrics_list)) {
    # Extract abs_bias, ci_lower, and ci_upper for the current condition
    abs_bias <- metrics_list[[condition]]$abs_bias
    ci_lower <- metrics_list[[condition]]$ci_lower
    ci_upper <- metrics_list[[condition]]$ci_upper
    
    # Create the bias_ci table for the current condition and store it in the list
    bias_ci[[condition]] <- abs_bias %>%
      mutate(across(`50`:`100`, ~pmap_chr(list(abs_bias[[cur_column()]], ci_lower[[cur_column()]], ci_upper[[cur_column()]]),
                                            ~sprintf("%.3f [%.3f-%.3f]", ..1, ..2, ..3)),
             .names = "{.col}_formatted")) %>%
      select(method_metric, ends_with("formatted")) %>%
      rename_all(~sub("_formatted$", "", .))
  }
  
  return(bias_ci)
}


```

#  Simulation Study
```{r}
simulation_study_ <- function(design){
  all_steps <- mutate(design, !!!future_pmap_dfr(design, planned_analysis, .options = furrr_options(seed = TRUE)))
  all_steps
}

simulation_study <- function(design, k, seed = NULL) {
  # Define a function to run simulation_study_() safely
  safe_simulation <- function(design) {
    # Run the simulation function safely
    result <- quietly(safely(simulation_study_))(design)
    
    # Extract the output, errors, and warnings: Question: On which level do we want this? Do obtain the correct DF, triple indexing into safely() is  necessary.
    output <- if (!is.null(result$error)) NULL else result$result$result
    errors <- if (!is.null(result$error)) result$error else NULL
    warnings <- if (!is.null(result$warning)) result$warning else NULL
    messages <- result$message
    
    # Return a list with the output, errors, and warnings
    list(result = output, errors = errors, warnings = warnings, messages = messages)
  }
  
  # Run simulation_study_() k times, capturing errors and warnings
  results_list <- future_map(seq_len(k), ~safe_simulation(design), .options = furrr_options(seed = seed))
  
  # Extract result, errors, and warnings from the list
  results <- map_df(results_list, pluck, "result")
  errors <- map(results_list, pluck, "errors")
  warnings <- map(results_list, pluck, "warnings")
  messages <- map(results_list, pluck, "messages")
  
  # Combine results, errors, and warnings into a single data frame

  return(list(results = results, errors = errors, warnings = warnings, messages = messages))
}

```

## Run simulation
```{r}

#Set up design
design <- setup_design()

#Run simulation
results_sim <- simulation_study(design, 2, seed = TRUE)

#Errors, warnings and messages?
errors <- results_sim$errors
warnings <- results_sim$warnings
messages <- results_sim$messages

#Output and extract results
results_df_raw <- results_sim$results
metrics_list <- extract_results(results_df_raw)

#Report Bias
bias_ci <- report_bias(metrics_list)
bias_ci

```
