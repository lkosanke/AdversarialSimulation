# First script for Simulation Study 1b

```{r}
set.seed(1)
```

# Packages

Copied and pasted from original paper.

```{r}
# Specify the libraries to load
libraries <- c("GPArotation", "CDM", "miceadds", "TAM", "sirt", "lavaan", "dplyr", "tidyr", "purrr", "tidyverse", "furrr")
# Set the R mirror to the cloud mirror of RStudio
options(repos = "https://cloud.r-project.org/")

# Load the libraries
for (library_name in libraries) {
  if (!require(library_name, character.only = TRUE)) {
    install.packages(library_name)
    library(library_name, character.only = TRUE)
  }
}
```

# Specify 2-factor-Model
```{r}
model <- "

#Structural part
    FX =~ l1*X1 + l2*X2 + l3*X3
    FY =~ l4*Y1 + l5*Y2 + l6*Y3
    FX ~~ 1*FX    #Fixed latent variance
    FY ~~ 1*FY    #Fixed latent variance
    FX ~~ phi*FY
    phi < 0.99    #Phi between -1 and 1
    phi > -0.99

#Measurement part    
    X1 ~~ vX1*X1
    X2 ~~ vX2*X2    
    X3 ~~ vX3*X3
    Y1 ~~ vY1*Y1
    Y2 ~~ vY2*Y2    
    Y3 ~~ vY3*Y3
    l1 > 0.01     #only positive loadings
    l2 > 0.01    
    l3 > 0.01
    l4 > 0.01
    l5 > 0.01
    l6 > 0.01       
    vX1 > 0.01    #only positive variances
    vX2 > 0.01    
    vX3 > 0.01
    vY1 > 0.01
    vY2 > 0.01    
    vY3 > 0.01
                #residual correlations
    X1 ~~ Y1
    X2 ~~ Y2
    "
```

# Setup and Design

```{r}
setup_design <- function() {
  
  #N
  N_sizes <- c(50, 100)
  
  # Factor loadings
  lambda_values <- c(0.4, 0.5, 0.6, 0.7, 0.8)
  
  # Factor correlations
  phi_values <- c(0, 0.2, 0.4, 0.6, 0.8)
  
  # Expand grid to create a data frame of all combinations
  design <- expand.grid(N = N_sizes, 
                        lambda = lambda_values, 
                        phi = phi_values)
  
  return(design)
}


```

# Data generating Mechanism

## Fixed values
No fixed values

## Varying values
```{r}
get_dgm <- function(lambda, phi) {
  # Factor loadings for all six manifest variables set to the specified lambda
  LAM <- matrix(c(lambda, lambda, lambda, lambda, lambda, lambda), nrow = 6, ncol = 2, byrow = TRUE)
  LAM[1:3, 2] <- 0  # Setting off-diagonal elements to 0
  LAM[4:6, 1] <- 0  
  
  # Factor correlation matrix
  PHI <- matrix(c(1, phi, phi, 1), nrow = 2, ncol = 2)
  
  # Theta
  error_variances <- 1 - lambda^2  
  THETA <- diag(c(rep(error_variances, 6)))  
  
  # residual correlations are directly specified 
  THETA[1, 4] <- THETA[4, 1] <- 0.12  
  THETA[2, 5] <- THETA[5, 2] <- 0.12 

  MLIST <-list(LAM = LAM, PHI = PHI, THETA = THETA)
  return(MLIST)
}


```

# Apply Syntax
```{r}
apply_syntax <- function(MLIST) {
  
  LAM <- MLIST$LAM
  PHI <- MLIST$PHI
  THETA <- MLIST$THETA
  
  pop.model <- paste(
"#Structural part",
    paste("FX =~", LAM[1,1], "*X1 +", LAM[2,1], "*X2 +", LAM[3,1], "*X3"),
    paste("FY =~", LAM[4,2], "*Y1 +", LAM[5,2], "*Y2 +", LAM[6,2], "*Y3"),
    "FX ~~ 1*FX",    
    "FY ~~ 1*FY",    
    paste("FX ~~", PHI[1,2], "*FY"),
"#Measurement part",    
    paste("X1 ~~", THETA[1,1], "*X1"),
    paste("X2 ~~", THETA[2,2], "*X2"),
    paste("X3 ~~", THETA[3,3], "*X3"),
    paste("Y1 ~~", THETA[4,4], "*Y1"),
    paste("Y2 ~~", THETA[5,5], "*Y2"),
    paste("Y3 ~~", THETA[6,6], "*Y3"),
"Correlated residuals",
    paste("X1 ~~", THETA[1,4], "*Y1"),
    paste("X2 ~~", THETA[2,5], "*Y2"),
    sep = "\n"
  ) 
 
  return(pop.model)
}

model_syntax <-apply_syntax(get_dgm(0.4,0.2))
cat(model_syntax)

```


# Simulate data
```{r}
simulate_data <- function(N, lambda, phi) {

  dgm_params <- get_dgm(lambda, phi)
  
  pop.model <- apply_syntax(dgm_params)
  
  df_dat <- simulateData(pop.model, sample.nobs = N)
  
  return(df_dat)
}

```

# Planned Analysis
```{r}
#Specify estimation methods of interest

estimators <- list(
  LSAM_ML = \(d) lavaan::sam(model, data=d, sam.method="local", estimator = "ML", std.lv= TRUE),
  LSAM_ULS = \(d)lavaan::sam(model, data=d, sam.method="local", estimator = "ULS", std.lv= TRUE)
)
# postprocess each model output
estimators <- modify(estimators, ~compose(\(e)filter(e, label == "phi")$est, parameterEstimates, .))
# apply all estimators to the same dataset
apply_estimators <- \(d) map(estimators, exec, d)

planned_analysis <- compose(apply_estimators, simulate_data)

planned_analysis(100, 0.4, 0.2)

```
# Extract results

```{r}

extract_results <- function(results_df_raw){
#Compute performance measures
results_metrics <- results_df_raw %>%
    group_by(N, lambda, phi) %>%
    summarize(across(everything(),
       list(
          abs_bias = ~mean(abs(.x - phi)),              # Average absolute bias
          rel_bias = ~mean(.x - phi) / phi,             # Relative bias
          sd = ~sd(.x),                                 # Standard deviation of estimates
          rmse = ~sqrt(mean((.x - phi)^2)),             # Root mean square error
          se_bias = ~(sd(abs(.x - phi)))/ sqrt(unique(N)),      # SE of bias
          ci_lower = ~(mean(abs(.x - phi)) - qt(0.975, df = unique(N) - 1) * (sd(abs(.x - phi)))/ sqrt(unique(N))),  # Lower CI
          ci_upper = ~(mean(abs(.x - phi)) + qt(0.975, df = unique(N) - 1) * (sd(abs(.x - phi)))/ sqrt(unique(N)))   # Upper CI
                    )),  .groups = 'drop')

  # Split metrics by rc and psi_value into separate lists
  split_metrics <- results_metrics %>%
    group_by(rc, psi_value) %>%
    group_split() %>%
    set_names(map(., ~paste(unique(.x$rc), unique(.x$psi_value), sep="_")))

  # Define a function to transform each group into the desired format
  transform_group <- function(df_group) {
    df_group <- df_group %>%
      select(-rc, -psi_value) %>%
      pivot_longer(cols = starts_with(c("SEM_","LSAM_","GSAM_")), names_to = "method_metric", values_to = "value")

    # Creating nested lists for each metric
    list(
      abs_bias = df_group %>% filter(str_detect(method_metric, "abs_bias")) %>%
              pivot_wider(names_from = N, values_from = value),
      rel_bias = df_group %>% filter(str_detect(method_metric, "rel_bias")) %>%
                 pivot_wider(names_from = N, values_from = value),
      sd = df_group %>% filter(str_detect(method_metric, "sd")) %>%
              pivot_wider(names_from = N, values_from = value),
      rmse = df_group %>% filter(str_detect(method_metric, "rmse")) %>%
              pivot_wider(names_from = N, values_from = value),
      se_bias = df_group %>% filter(str_detect(method_metric, "se_bias")) %>%
                pivot_wider(names_from = N, values_from = value),
      ci_lower = df_group %>% filter(str_detect(method_metric, "ci_lower")) %>%
                pivot_wider(names_from = N, values_from = value),
      ci_upper = df_group %>% filter(str_detect(method_metric, "ci_upper")) %>%
                pivot_wider(names_from = N, values_from = value)
    )
  }

  # Apply the transformation to each group and store the results
  metrics_list <- map(split_metrics, transform_group)

  return(metrics_list)
}

```


#  Simulation Study
```{r}
simulation_study <- function(design, model, num_repetitions, models) {
  # Initialize an empty dataframe to store the results
  results_df <- data.frame(
    ModelType = character(),
    N = integer(),
    Lambda = numeric(),
    Phi = numeric(),
    AvgAbsBias = numeric(),
    stringsAsFactors = FALSE
  )
  
  for(model_type in models) {
    for(i in 1:nrow(design)) {
      row <- design[i, ]
      N <- row$N
      lambda <- row$lambda
      phi_true <- row$phi  # Use phi from the design matrix as the true value
      
      phi_estimates <- replicate(num_repetitions, {
        planned_analysis(N, lambda, phi_true, model, model_type)
      }, simplify = "array")
      
      # Calculate the average absolute bias of the estimated phi
      avg_abs_bias <- mean(abs(phi_estimates - phi_true))
      
      # Append the results to the results dataframe
      results_row <- data.frame(
        ModelType = model_type,
        N = N,
        Lambda = lambda,
        Phi = phi_true,
        AvgAbsBias = avg_abs_bias
      )
      
      results_df <- rbind(results_df, results_row)
    }
  }
  
  return(results_df)
}



```

## RUN
```{r}
design <- setup_design()
models <- c("LSAM_ML", "LSAM_ULS")  # Models to test
num_repetitions <- 2

# Execute the simulation study
results_df <- simulation_study(design, model, num_repetitions, models)

# View the results
print(results_df)


```

# Report analysis
```{r}
report_analysis <- function(results_df) {
  # List to store the final tables
  tables_list <- list()
  
  # Extract unique model types and N values
  model_types <- unique(results_df$ModelType)
  N_values <- unique(results_df$N)
  
  # Create a table for each combination of ModelType and N
  for (model in model_types) {
    for (N_size in N_values) {
      
      # Filter the dataframe for the current ModelType and N
      subset_df <- results_df %>%
        filter(ModelType == model, N == N_size)%>%
        mutate(AvgAbsBias = round(AvgAbsBias, 2))
      
      # Pivot the dataframe to wide format with Lambda as rows and Phi as columns
      wide_df <- subset_df %>%
        select(Lambda, Phi, AvgAbsBias) %>%
        pivot_wider(names_from = Phi, values_from = AvgAbsBias, names_prefix = "Phi_") %>%
        arrange(Lambda)

      # Create a name for each table based on ModelType and N
      table_name <- paste0(model, "_N_", N_size)
      tables_list[[table_name]] <- wide_df
    }
  }
  
  return(tables_list)
}

# Run the function with results
list_of_tables <- report_analysis(results_df)

# Access a specific table
LSAM_ML_N_50 <- list_of_tables[["LSAM_ML_N_50"]] 

#display all tables
report_analysis(results_df)
```


