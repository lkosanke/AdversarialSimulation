---
title: "Master Thesis Proposal"
format: pdf
author:
    - Valentin Krimair
    - Leo Kosanke
bibliography: bibliography.bib
---

# Introduction

Monte Carlo simulations are an extensively utilized tool for assessing and comparing statistical methods in quantitative empirical science. Their key advantage lies in the ability to evaluate the performance of estimation and inference methods by analyzing them in light of known simulated population models and values. Despite the clear insight into the explicitly specified underlying data structures that simulations provide, they are not immune to common pitfalls that thus far have been predominantly associated with the replication crisis in empirical quantitative research [@lohmann_its_2022]. In simulation studies, a key challenge is ensuring that results can be generalized to real-world applications. These studies must ensure that the chosen performance metrics, experimental factors, and inference models accurately reflect and test the complexities and variability of real-world scenarios. Given the impracticality of simulating and analyzing every possible inference model and use case, these studies inherently involve a multitude of decision-making elements potentially prone to bias. Further, the decisions of selecting evaluation criteria, target models and simulation specifications can have substantive impact on the results. One approach that addresses these issues at the level of population model selection empirically grounds this decision by sampling from model configurations in the scientific literature [@bollmann_what_2015].

Here we propose a novel approach to address generalizability as well as biases on all decision-making elements of simulation studies. We aim to introduce and test an adversarial collaboration framework for simulation studies. The approach is tailored for comparison studies in particular, which are critical in the validation of new statistical methods. This aligns with the recognized need for neutral and rigorous assessment in such studies [@boulesteix_plea_2013]. Adversarial collaboration, piloted by [@mellers_frequency_2001] and popularized by [@kahneman_thinking_2011], is a research method increasingly recognized within the quantitative empirical research community for enhancing scientific rigor. Praised as “The next science reform” [@clark_adversarial_2021] adversarial collaboration is the process of disagreeing scholars working jointly to resolve scientific disputes. This method entails identifying points of empirical disagreement, designing mutually agreed upon methods to test competing hypotheses, and jointly publishing results, irrespective of the outcome. The authors highlight its role in promoting fair tests and truthful representation of opposing views, thereby enhancing epistemic accountability and reducing research ambiguity. Additionally, juxtaposing and debating competing positions in this way can improve generalizability of results.

Our goal is to transfer these benefits of adversarial collaboration to simulation studies. To do so, we want to conduct a focused case study: comparing a newly proposed iterative structural after measurement (SAM) estimation approach to structural equation model (SEM) estimation with traditional non-iterative SEM estimation [@dhaene_evaluation_2023, @robitzsch_comparing_2022, @rosseel_structural_2022]. In their respective simulations, the authors results differed up to the point of contradiction, providing us with ideal grounds for conducting adversarial collaboration. While @dhaene_evaluation_2023 concluded that SAM estimation generally outperforms non-iterative SEM in small samples, @robitzsch_comparing_2022 did not find the methods to differ. Similarly, whereas the former found SAM to be more robust against model misspecification, the latter argued the opposite to be true. The idea is that we, the authors of this paper, represent these competing positions, with each of us advocating for one of the different set of findings, as detailed later. This allows us to examine the practical feasibility of adversarial collaboration in Monte Carlo simulation studies as well its potential to enhance methodological rigor and generalizability in this domain of research. Hence, such an investigation will lead us to address the following research question:

By applying our adversarial collaboration framework to the comparison of iterative structural after measurement (SAM) and traditional non-iterative estimation of structural equation models (SEM), can we demonstrate its practical applicability and technical feasibility for conducting Monte Carlo simulation studies?

# Method

To answer this research question, we created the following procedure to be conducted for the adversarial collaboration process:

## Outline

In general, the procedure consists of two parts. In the first part, each researcher conducts an independent preliminary study as a replication of their side of the argument. Leonard Kosanke will be replicating relevant parts of the study by \textcite{robitzsch_comparing_2022], and Valentin Kriegmair will replicate the study by \textcite{dhaene_evaluation_2023]. The replications include the generation of individual simulation protocols, as suggested by \textcite{morris_using_2019].

In the second part, a joint study, including a joint simulation protocol, is pursued. Here, the main part of the adversarial collaboration takes place. Each step of the individual simulation studies (from the substantive research question up until the interpretation of the results) is scrutinized and debated between collaborators, using adversarial collaboration techniques as listed below. Decisions are made and documented based on the most convincing argument presented, if possible. This process starts based on the results of Part 1, which could include contradictory findings, subjective interpretations of ambiguous results, or strong opinions on expected outcomes as a consequence of the preliminary results.

To facilitate a structured comparison and the integration of our studies through the collaboration process, we have established a common framework for conducting our individual simulation studies. This framework allows for the expected divergences in results while providing a basis for systematic comparison and synthesis. Additionally, we have identified two substantive research questions to co-align the individual simulation studies:

1. How do SAM and traditional SEM methods (including ML and ULS) compare in terms of bias, Mean Squared Error (MSE), and convergence rates in small to moderate samples?
2. What is the impact of model misspecifications, such as residual correlations and cross-loadings, on the performance of SAM compared to traditional SEM methods?

In the end, each collaborator will report all results in their own thesis.

## Adversarial Collaboration (AC) Techniques

At each step of decision making in the Joint Study, any of the following techniques can be used, depending on their applicability: [List of techniques]

## Documentation - Decision log

The results of the Joint Study will be presented in the main papers in a concise way, focussing on the most crucial decisions. [Further details on documentation.]

## Evaluation - Diary entries

The adversarial collaboration in Part 2 (Joint study), is documented and evaluated from each collaborator's perspective using semi-structured diary entries. [Further details on evaluation.]

# Timetable

Upon receiving approval, we aim to conduct the individual simulation studies until March 15, 2024. The joint study is scheduled to commence immediately afterward, from March 16 to April 15, 2024. Finally, the period from April 16 to April 30, 2024, will be dedicated to writing our respective theses.

(Note: In Markdown, there is no direct equivalent for the `\printbibliography` command used in LaTeX. References are typically listed manually or linked in-line within the text.)
